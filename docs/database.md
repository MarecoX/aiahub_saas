# üíæ Banco de Dados (PostgreSQL)

O Kestra 2.0 utiliza PostgreSQL como fonte √∫nica de verdade (Single Source of Truth), com uma arquitetura **Multi-Tenant L√≥gica** (todos os clientes no mesmo banco, separados por ID).

## üóÑÔ∏è Diagrama Entidade-Relacionamento (ER)

```mermaid
erDiagram
    clients ||--o{ chat_messages : "possui"
    clients ||--o{ client_files : "possui"
    clients ||--o{ client_providers : "possui"
    clients ||--o{ reminders : "possui"

    clients {
        UUID id PK "Identificador √önico do Tenant"
        VARCHAR name "Nome da Empresa"
        TEXT system_prompt "Personalidade da IA"
        JSONB tools_config "Configura√ß√µes de TOOLS"
        TIMESTAMP created_at
    }

    client_providers {
        UUID id PK
        UUID client_id FK "Cliente dono"
        VARCHAR provider_type "uazapi | meta | lancepilot"
        VARCHAR instance_name "Principal | Loja 2..."
        JSONB config "Credenciais do provider"
        BOOLEAN is_active
        BOOLEAN is_default
    }

    reminders {
        UUID id PK
        UUID client_id FK
        VARCHAR chat_id "Telefone do lead"
        TIMESTAMP scheduled_at "Quando enviar"
        TEXT message "Motivo/contexto"
        VARCHAR status "pending | sent | cancelled"
    }

    active_conversations {
        TEXT chat_id PK "Telefone/ID do Cliente Final"
        UUID client_id PK,FK "Dono da Conversa"
        TEXT status "active | finished"
        INT followup_stage "Est√°gio do Funil (0-5)"
        TEXT last_role "Quem falou por √∫ltimo"
        TIMESTAMP last_message_at "Para c√°lculo de inatividade"
        TEXT last_context "Resumo acumulado para o RAG"
    }

    chat_messages {
        SERIAL id PK
        UUID client_id FK "Dono da Mensagem"
        TEXT chat_id "Telefone do Cliente Final"
        TEXT role "user | assistant"
        TEXT content "Texto da Mensagem"
        TEXT media_url "Link S3/Meta (Opcional)"
        TIMESTAMP created_at
    }

    client_files {
        UUID id PK
        UUID client_id FK
        VARCHAR filename
        VARCHAR file_hash UK "Para evitar duplicatas"
        VARCHAR google_file_uri "URI no Gemini File API"
    }

    clients ||--o{ conversation_events : "registra"
    clients ||--o{ metrics_daily : "agrega"

    conversation_events {
        BIGSERIAL id PK
        UUID client_id FK
        TEXT chat_id "Conversa"
        VARCHAR event_type "msg_received | ai_responded | human_takeover..."
        JSONB event_data "Dados extras do evento"
        TIMESTAMPTZ created_at
    }

    metrics_daily {
        BIGSERIAL id PK
        UUID client_id FK
        DATE date "Dia da agregacao"
        INT total_conversations
        INT resolved_by_ai
        INT resolved_by_human
        INT human_takeovers
        INT avg_response_time_ms
        DECIMAL total_cost_usd
        JSONB tools_used "Contagem por tool"
    }
```

## üìã Detalhe das Tabelas

### 1. `clients` (Mestre)
A tabela mais importante. Cada linha representa um **SaaS Tenant** (uma empresa cliente).

| Coluna | Tipo | Descri√ß√£o |
| :--- | :--- | :--- |
| `id` | UUID | Gerado automaticamente (`gen_random_uuid()`). Chave Prim√°ria. |
| `name` | VARCHAR | Nome da empresa cliente. |
| `tools_config` | JSONB | Configura√ß√µes das **Tools da IA** (consultar_cep, enviar_relatorio, criar_lembrete, etc). |

> **ADR-002 (2026-01):** O campo `token` foi **deprecado**. Credenciais de providers agora ficam em `client_providers`.

#### Exemplo de `tools_config` (JSONB):
```json
{
  "consultar_cep": {"active": true},
  "criar_lembrete": {"active": true},
  "enviar_relatorio": {"active": true, "grupo_id": "123..."},
  "consultar_viabilidade_hubsoft": {"active": true, "api_url": "...", "client_id": "..."}
}
```

### 2. `client_providers` (Provedores de Comunica√ß√£o)
**Nova tabela (2026-01).** Armazena credenciais dos providers de WhatsApp.

| Coluna | Tipo | Descri√ß√£o |
| :--- | :--- | :--- |
| `id` | UUID | Chave Prim√°ria. |
| `client_id` | UUID | FK para `clients`. |
| `provider_type` | VARCHAR | `uazapi`, `meta`, ou `lancepilot`. |
| `instance_name` | VARCHAR | Nome da inst√¢ncia (ex: "Principal", "Loja 2"). |
| `config` | JSONB | Credenciais espec√≠ficas do provider. |
| `is_active` | BOOLEAN | Se est√° ativo. |
| `is_default` | BOOLEAN | Se √© o provider padr√£o. |

#### Exemplo de `config` por provider:
```json
// Uazapi
{"url": "https://api.z-api.io/...", "token": "abc123..."}

// Meta (Oficial)
{"phone_id": "123...", "access_token": "EAA...", "waba_id": "..."}

// LancePilot
{"token": "...", "workspace_id": "...", "number": "..."}
```

### 3. `reminders` (Lembretes Agendados)
**Nova tabela (2026-01).** Armazena lembretes para follow-up agendado.

| Coluna | Tipo | Descri√ß√£o |
| :--- | :--- | :--- |
| `id` | UUID | Chave Prim√°ria. |
| `client_id` | UUID | FK para `clients`. |
| `chat_id` | VARCHAR | Telefone do lead. |
| `scheduled_at` | TIMESTAMP | Quando enviar o lembrete. |
| `message` | TEXT | Motivo/contexto do lembrete. |
| `status` | VARCHAR | `pending`, `sent`, `cancelled`, `error`. |

### 4. `active_conversations` (State Machine)
Tabela vital para os **Workers de Follow-up**. Ela mant√©m o "estado atual" de cada conversa, permitindo que os scripts saibam quem precisa de resposta ou reengajamento.
*   **Chave Prim√°ria Composta:** `(chat_id, client_id)`. Garante 1 estado por cliente/conversa.
*   **`followup_stage`:** Controla em qual passo do funil de vendas o cliente est√°.
*   **`last_context`:** Uma "mem√≥ria de curto prazo" que os Workers consultam para n√£o perder o fio da meada.

### 5. `chat_messages` (Hist√≥rico)
Armazena o hist√≥rico de conversa para exibir na interface "Inbox 2.0" e para fornecer contexto ("Mem√≥ria") para a IA.
*   **Particionamento:** Os dados n√£o s√£o fisicamente separados. A seguran√ßa √© garantida pela cl√°usula `WHERE client_id = ...` em todas as queries no `saas_db.py`.


## üìä Arquitetura de M√©tricas (Proposta ADR-003)

Para escala e an√°lise de m√©tricas da IA, o sistema adota **3 camadas**: Event Log + Agrega√ß√£o Pr√©-calculada + Leitura Instant√¢nea.

### Camada 1: `conversation_events` (Source of Truth)

Tabela append-only que registra cada transi√ß√£o de forma imut√°vel. Custo: 1 INSERT por evento (~0ms extra).

```sql
CREATE TABLE conversation_events (
    id          BIGSERIAL PRIMARY KEY,
    client_id   UUID NOT NULL REFERENCES clients(id),
    chat_id     TEXT NOT NULL,
    event_type  VARCHAR(50) NOT NULL,
    event_data  JSONB DEFAULT '{}',
    created_at  TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_conv_events_client_time ON conversation_events (client_id, created_at);
CREATE INDEX idx_conv_events_chat ON conversation_events (client_id, chat_id, created_at);
CREATE INDEX idx_conv_events_type ON conversation_events (event_type, created_at);
```

**Tipos de evento (`event_type`):**

| Evento | Descri√ß√£o | `event_data` exemplo |
| :--- | :--- | :--- |
| `msg_received` | Mensagem do usu√°rio final | `{"source": "uazapi"}` |
| `ai_responded` | IA gerou resposta | `{"response_time_ms": 1200, "tokens": 350}` |
| `human_takeover` | Humano assumiu atendimento | `{"reason": "tool_call"}` |
| `human_responded` | Humano respondeu | `{}` |
| `followup_sent` | Follow-up disparado | `{"stage": 2}` |
| `resolved` | Conversa resolvida | `{"resolved_by": "ai"}` |
| `tool_used` | Tool executada pela IA | `{"tool": "consultar_viabilidade_hubsoft"}` |

### Camada 2: `metrics_daily` (Agrega√ß√£o Pr√©-calculada)

Tabela atualizada por um worker peri√≥dico (cron 5-15 min). O dashboard l√™ **somente desta tabela** = queries instant√¢neas.

```sql
CREATE TABLE metrics_daily (
    id                      BIGSERIAL PRIMARY KEY,
    client_id               UUID NOT NULL REFERENCES clients(id),
    date                    DATE NOT NULL,
    total_conversations     INT DEFAULT 0,
    total_messages_in       INT DEFAULT 0,
    total_messages_out      INT DEFAULT 0,
    resolved_by_ai          INT DEFAULT 0,
    resolved_by_human       INT DEFAULT 0,
    human_takeovers         INT DEFAULT 0,
    avg_response_time_ms    INT DEFAULT 0,
    avg_resolution_time_ms  INT DEFAULT 0,
    followups_sent          INT DEFAULT 0,
    followups_converted     INT DEFAULT 0,
    tools_used              JSONB DEFAULT '{}',
    total_cost_usd          DECIMAL(10,4) DEFAULT 0,
    updated_at              TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE (client_id, date)
);
```

### Camada 3: Worker de Agrega√ß√£o (Kestra Cron)

Um worker que roda a cada 5 minutos agrega os eventos em `metrics_daily` via `UPSERT`:

```
conversation_events (append-only)
    ‚îÇ
    ‚îî‚îÄ‚îÄ metrics_worker (cron 5min)
            ‚îÇ
            ‚îî‚îÄ‚îÄ UPSERT metrics_daily
                    ‚îÇ
                    ‚îî‚îÄ‚îÄ Dashboard l√™ (instant√¢neo)
```

### M√©tricas Deriv√°veis

Com o event log, qualquer m√©trica pode ser calculada:

| M√©trica | F√≥rmula |
| :--- | :--- |
| Taxa de resolu√ß√£o IA | `resolved_by_ai / total_conversations` |
| Taxa de handoff humano | `human_takeovers / total_conversations` |
| Tempo m√©dio de resposta | `avg_response_time_ms` |
| Efic√°cia de followup | `followups_converted / followups_sent` |
| Hor√°rios de pico | `GROUP BY EXTRACT(HOUR FROM created_at)` |
| Custo por conversa | `total_cost_usd / total_conversations` |
| Tools mais usadas | Agrega√ß√£o do campo `tools_used` |

> **Por que n√£o query ao vivo?** Queries de agrega√ß√£o sobre `chat_messages` e `active_conversations` em tempo real ficam lentas com escala (full table scan). A camada de pr√©-agrega√ß√£o garante que o dashboard sempre responde em <50ms independente do volume de dados.

---

## ‚öôÔ∏è Acesso a Dados (DAO)

Todo o acesso √© centralizado no m√≥dulo `scripts/shared/saas_db.py`.

### Connection Pooling
N√£o abrimos uma conex√£o por requisi√ß√£o (isso mataria o banco). Usamos `psycopg_pool`.
*   O Pool mant√©m conex√µes vivas e as reusa.
*   **`max_size`**: Configur√°vel via vari√°vel de ambiente `DB_POOL_MAX_SIZE` (default: 5).
*   **`timeout`**: 30 segundos para evitar travamentos.

### Configura√ß√£o via Ambiente
```bash
# No .env ou docker-compose
DB_POOL_MAX_SIZE=10  # Aumenta para 10 conex√µes por container
```

### PostgreSQL `max_connections`
Para escalar, aumente `max_connections` no PostgreSQL:
```yaml
# docker-compose.yaml
services:
  postgres:
    command: postgres -c max_connections=500 -c shared_buffers=512MB
```

### Padr√£o Singleton
O pool √© inicializado apenas uma vez por processo Python.
```python
# saas_db.py
_pool = ConnectionPool(
    conninfo=DB_URL,
    min_size=1,
    max_size=DB_POOL_MAX_SIZE,  # Configur√°vel via env
    timeout=30.0,
)

def get_connection():
    return _pool.connection()  # Empresta uma conex√£o
```

### Controle de Concorr√™ncia (Kestra)
Para evitar esgotar conex√µes, os flows usam `concurrency`:
```yaml
concurrency:
  limit: 10      # M√°ximo 10 execu√ß√µes simult√¢neas
  behavior: QUEUE  # Extras entram em fila
```

